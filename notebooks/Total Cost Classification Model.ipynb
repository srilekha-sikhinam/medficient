{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Cost Model Building and Exploration \n",
    "\n",
    "This notebook shows the process of building classification models for Total Costs. It shows the performance of models with different bin sizes, different models, and upsampling techniques. This notebook also contains an evaluation of model performance across sub-populations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will be importing all necessary libraries required for our Random Forest classification, and we will looking at various metrics including the accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all needed models\n",
    "import sys\n",
    "import platform\n",
    "plat = platform.system()\n",
    "if plat == 'Windows':\n",
    "    sys.path.insert(0, '..\\src\\helpers')\n",
    "    sys.path.insert(0, '..\\src\\models')\n",
    "elif plat =='Linux' or plat=='Darwin':\n",
    "    sys.path.insert(0, '../src/helpers')\n",
    "    sys.path.insert(0, '../src/models')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import log_loss, f1_score, classification_report, make_scorer, precision_score, recall_score, accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "import seaborn as sns\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below two cells must be run at all times in order to bring in the helper functions for the models and additonally clean data further for data modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_cleaners import *\n",
    "from model_building_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all patient csv (csv containing data for all the indications (COPD, Heart Failure, Schizophrenia, Knee Replacement, Kidney/UTI))\n",
    "data_file_path = '../data'\n",
    "all_patient_df = load_data('All', data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 1 - Creating Bins for Total Cost\n",
    "\n",
    "We will first create different bins for our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxcost = all_patient_df['Total Costs'].max()\n",
    "print(\"Maximum Total Cost:\", maxcost)\n",
    "\n",
    "#Bin the data by length of stay ranges\n",
    "bins = [1, 5000, 10000, 15000, 20000, 30000, 50000, 1250000]\n",
    "labels = ['1 - 5000', '5001 - 10000', '10001 - 15000', '15001 - 20000'\n",
    "          , '20001 - 30000', '30001 - 50000', '50001 - 1250000']\n",
    "\n",
    "all_patient_df_bins = all_patient_df.copy()\n",
    "all_patient_df_bins['Total Costs Bin'] = pd.cut(x = all_patient_df_bins['Total Costs'], \n",
    "                                                bins = bins, labels = labels, include_lowest = True)\n",
    "all_patient_df_bins.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 8))\n",
    "plt.title('Count Plot for Cost Bins', fontsize=12, weight='bold', pad=30)\n",
    "sns.countplot(data=all_patient_df_bins, y=\"Total Costs Bin\", palette=['skyblue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 2 - Train model on Hist Gradient Boosting Classfier\n",
    "This will help us with understanding the Accuracy and F1-scores of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_train, X_test, y_train, y_test = get_cost_train_test_data(all_patient_df_bins)\n",
    "\n",
    "model = HistGradientBoostingClassifier()\n",
    "model.fit(X_train, np.ravel(y_train))\n",
    "y_pred = model.predict(X_test)\n",
    "bin1_accuracy = accuracy_score(y_test, y_pred)\n",
    "bin1_f1_score_macro = f1_score(y_test, y_pred, average='macro')\n",
    "bin1_f1_score_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy = \", bin1_accuracy, \"\\nF1 Macro Score = \", bin1_f1_score_macro, \"\\nF1 Weighted Score = \", bin1_f1_score_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the confusion matrix as a heart map\n",
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix), index = [i for i in labels],\n",
    "                  columns = [i for i in labels])\n",
    "plt.figure(figsize = (12, 12))\n",
    "plt.title('Confusion Matrix For HistGradientBoosting  Model', fontsize=17, weight='bold', pad=30)\n",
    "sns.heatmap(df_cm, annot=True, fmt='.2%',  cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Gradient Boost Classifier best parameters and best score by sub-population\n",
    "#Experiment model performance by changing the parameters tested and interations for the RandomizedSearch\n",
    "gb_scores = []\n",
    "iterations = 10 #We found the iterations did not affect F1 macro scores much, so we used the default of 10\n",
    "\n",
    "for drg in ['all', 194.0, 140.0, 750.0, 463.0, 302.0]:\n",
    "    subpop_df = load_data(drg, data_file_path)\n",
    "    subpop_df['Total Costs Bin'] = pd.cut(x = subpop_df['Total Costs'], bins = bins, labels = labels, \n",
    "                                          include_lowest = True)\n",
    "    if len(subpop_df) > 30000:\n",
    "        subpop_df = subpop_df.groupby('Total Costs Bin', group_keys=False).apply(\n",
    "            lambda x: x.sample(int(np.rint(30000*len(x)/len(subpop_df))))).sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "    X, y, X_train, X_test, y_train, y_test = get_cost_train_test_data(subpop_df)\n",
    "\n",
    "    random_grid = {'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "                   'learning_rate': [0.1 , 0.5 , 1],\n",
    "                   'min_samples_leaf': [1, 2, 4],\n",
    "                   'loss': ['log_loss', 'auto', 'binary_crossentropy','categorical_crossentropy']}\n",
    "    \n",
    "    best_params, best_score = get_best_gbc_params(X_train, y_train, random_grid, iterations)\n",
    "    gb_scores.append({drg:{\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score\n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get LogisticRegression best parameters and best score by sub-population\n",
    "#Experiment model performance by changing the parameters tested and interations for the RandomizedSearch\n",
    "lr_scores = []\n",
    "iterations = 10 #We found the iterations did not affect F1 macro scores much, so we used the default of 10\n",
    "\n",
    "for drg in ['all', 194.0, 140.0, 750.0, 463.0, 302.0]:\n",
    "    subpop_df = load_data(drg, data_file_path)\n",
    "    subpop_df['Total Costs Bin'] = pd.cut(x = subpop_df['Total Costs'], bins = bins, \n",
    "                                          labels = labels, include_lowest = True)\n",
    "    if len(subpop_df) > 30000:\n",
    "        subpop_df = subpop_df.groupby('Total Costs Bin', group_keys=False).apply(\n",
    "            lambda x: x.sample(int(np.rint(30000*len(x)/len(subpop_df)\n",
    "                                          )\n",
    "                                  )\n",
    "                              )).sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "    X, y, X_train, X_test, y_train, y_test = get_cost_train_test_data(subpop_df)\n",
    "\n",
    "    random_grid = {'C' : np.logspace(0, 4, num=10),\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'solver' : ['liblinear'],\n",
    "    'class_weight': ['balanced', None]}\n",
    "    \n",
    "    best_params, best_score = get_best_lr_params(X_train, y_train, random_grid, iterations)\n",
    "    lr_scores.append({drg:{\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score\n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Random Forest best parameters and best score by sub-population\n",
    "#Experiment model performance by changing the parameters tested and interations for the RandomizedSearch\n",
    "rf_scores = []\n",
    "iterations = 10 #We found the iterations did not affect F1 macro scores much, so we used the default of 10\n",
    "\n",
    "for drg in ['all', 194.0, 140.0, 750.0, 463.0, 302.0]:\n",
    "    subpop_df = load_data(drg, data_file_path)\n",
    "    subpop_df['Total Costs Bin'] = pd.cut(x = subpop_df['Total Costs'], bins = bins, \n",
    "                                          labels = labels, include_lowest = True)\n",
    "    if len(subpop_df) > 30000:\n",
    "        subpop_df = subpop_df.groupby('Total Costs Bin', group_keys=False).apply(\n",
    "            lambda x: x.sample(int(np.rint(30000*len(x)/len(subpop_df)\n",
    "                                          )\n",
    "                                  )\n",
    "                              )).sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "    X, y, X_train, X_test, y_train, y_test = get_cost_train_test_data(subpop_df)\n",
    "\n",
    "    random_grid = {'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 800, num = 15)],\n",
    "               'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False],\n",
    "               'class_weight': ['balanced', 'balanced_subsample']}\n",
    "    \n",
    "    best_params, best_score = get_best_rf_params(X_train, y_train, random_grid, iterations)\n",
    "    \n",
    "    rf_scores.append({drg:{\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score\n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_gb_df = pd.DataFrame(columns=['model', 'subpopulation', 'best_params', 'best_scores'])\n",
    "for item in gb_scores:\n",
    "    for key, item in item.items():\n",
    "        scores_gb_df = scores_gb_df.append({'model': 'HistGradientBoost', 'subpopulation': key, 'best_params': item['best_params'], 'best_scores': item['best_score']}, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_lr_df = pd.DataFrame(columns=['model', 'subpopulation', 'best_params', 'best_scores'])\n",
    "for item in lr_scores:\n",
    "    for key, item in item.items():\n",
    "        scores_lr_df = scores_lr_df.append({'model': 'LogRegression', 'subpopulation': key, 'best_params': item['best_params'], 'best_scores': item['best_score']}, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_rf_df = pd.DataFrame(columns=['model', 'subpopulation', 'best_params', 'best_scores'])\n",
    "for item in rf_scores:\n",
    "    for key, item in item.items():\n",
    "        scores_rf_df = scores_rf_df.append({'model': 'RandomForest', 'subpopulation': key, 'best_params': item['best_params'], 'best_scores': item['best_score']}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_search_results = pd.concat([scores_gb_df,scores_lr_df, scores_rf_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create visualization for each subpopulation for each model\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10), sharey=True)\n",
    "\n",
    "fig.subplots_adjust(hspace=0.45, wspace=0.25)\n",
    "\n",
    "\n",
    "fig.suptitle('F1 - Macro Scores For HistGradientBoostedClassifier vs. RandomForestClassifier vs. LogisticRegression\\n(Total Cost)', fontsize=17, weight='bold')\n",
    "\n",
    "\n",
    "all_patients = randomized_search_results[randomized_search_results['subpopulation'] == 'all']\n",
    "heart_patients = randomized_search_results[randomized_search_results['subpopulation'] == 194.0]\n",
    "copd_patients = randomized_search_results[randomized_search_results['subpopulation'] == 140.0]\n",
    "schizophrenia_patients = randomized_search_results[randomized_search_results['subpopulation'] == 750.0]\n",
    "kidney_patients = randomized_search_results[randomized_search_results['subpopulation'] == 463.0]\n",
    "knee_rep_patients = randomized_search_results[randomized_search_results['subpopulation'] == 302.0]\n",
    "\n",
    "sns.barplot(ax=axes[0, 0], x=all_patients['model'], y=all_patients['best_scores'], palette=['orangered', 'skyblue','#5CED73'])\n",
    "axes[0, 0].set_xlabel('Model Type', fontweight='bold', fontsize=14)\n",
    "axes[0, 0].set_ylabel('F1 Score', fontweight='bold', fontsize=14)\n",
    "axes[0, 0].bar_label(axes[0, 0].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[0, 0].set_xticklabels(labels=['Hist Gradient\\nBoosted\\nClassifier', 'Logistic\\nRegression', 'Random Forest\\nClassifier'], fontsize=14)\n",
    "axes[0, 0].set_title('All Patients', fontweight='bold', fontsize=16)\n",
    "current_values_y = axes[0, 0].get_yticks()\n",
    "axes[0, 0].set_yticklabels([round(x, 2) for x in current_values_y], fontsize=14)\n",
    "\n",
    "sns.barplot(ax=axes[0, 1], x=heart_patients['model'], y=heart_patients['best_scores'], palette=['orangered', 'skyblue','#5CED73'])\n",
    "axes[0, 1].set_xlabel('Model Type', fontweight='bold', fontsize=14)\n",
    "axes[0, 1].set_ylabel('F1 Score', fontweight='bold', fontsize=14)\n",
    "axes[0, 1].bar_label(axes[0, 1].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[0,1].set_xticklabels(labels=['Hist Gradient\\nBoosted\\nClassifier', 'Logistic\\nRegression', 'Random Forest\\nClassifier'], fontsize=14)\n",
    "axes[0, 1].set_title('Patients with DRG Code 194\\n(Heart Failure)', fontweight='bold', fontsize=16)\n",
    "\n",
    "sns.barplot(ax=axes[0, 2], x=copd_patients['model'], y=copd_patients['best_scores'], palette=['orangered', 'skyblue','#5CED73'])\n",
    "axes[0, 2].set_xlabel('Model Type', fontweight='bold', fontsize=14)\n",
    "axes[0, 2].set_ylabel('F1 Score', fontweight='bold', fontsize=14)\n",
    "axes[0, 2].bar_label(axes[0, 2].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[0, 2].set_xticklabels(labels=['Hist Gradient\\nBoosted\\nClassifier', 'Logistic\\nRegression', 'Random Forest\\nClassifier'], fontsize=14)\n",
    "axes[0, 2].set_title('Patients with DRG Code 140\\n(COPD)', fontweight='bold', fontsize=16)\n",
    "\n",
    "sns.barplot(ax=axes[1, 0], x=schizophrenia_patients['model'], y=schizophrenia_patients['best_scores'], palette=['orangered', 'skyblue','#5CED73'])\n",
    "axes[1, 0].set_xlabel('Model Type', fontweight='bold', fontsize=12)\n",
    "axes[1, 0].set_ylabel('F1 Score', fontweight='bold', fontsize=12)\n",
    "axes[1, 0].bar_label(axes[1, 0].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[1, 0].set_xticklabels(labels=['Hist Gradient\\nBoosted\\nClassifier', 'Logistic\\nRegression', 'Random Forest\\nClassifier'],  fontsize=14)\n",
    "axes[1, 0].set_title('Patients with DRG Code 750\\n(Schizophrenia)', fontweight='bold', fontsize=16)\n",
    "current_values_y = axes[1, 0].get_yticks()\n",
    "axes[1, 0].set_yticklabels([round(x, 2) for x in current_values_y], fontsize=14)\n",
    "\n",
    "sns.barplot(ax=axes[1, 1], x=kidney_patients['model'], y=kidney_patients['best_scores'], palette=['orangered', 'skyblue','#5CED73'])\n",
    "axes[1, 1].set_xlabel('Model Type', fontweight='bold', fontsize=14)\n",
    "axes[1, 1].set_ylabel('F1 Score', fontweight='bold', fontsize=14)\n",
    "axes[1, 1].bar_label(axes[1, 1].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[1, 1].set_xticklabels(labels=['Hist Gradient\\nBoosted\\nClassifier', 'Logistic\\nRegression', 'Random Forest\\nClassifier'], fontsize=14)\n",
    "axes[1, 1].set_title('Patients with DRG Code 463\\n(Kidney/UTI)', fontweight='bold', fontsize=16)\n",
    "\n",
    "sns.barplot(ax=axes[1, 2], x=knee_rep_patients['model'], y=knee_rep_patients['best_scores'], palette=['orangered', 'skyblue','#5CED73'])\n",
    "axes[1, 2].set_xlabel('Model Type', fontsize=14, fontweight='bold')\n",
    "axes[1, 2].set_ylabel('F1 Score', fontsize=14, fontweight='bold')\n",
    "axes[1, 2].bar_label(axes[1, 2].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[1, 2].set_xticklabels(labels=['Hist Gradient\\nBoosted\\nClassifier', 'Logistic\\nRegression', 'Random Forest\\nClassifier'], fontsize=14)\n",
    "axes[1, 2].set_title('Patients with DRG Code 302\\n(Knee Joint Replacement)', fontweight='bold', fontsize=16)\n",
    "\n",
    "axes[1, 2].set_ylim(0, 0.5)\n",
    "\n",
    "plt.tight_layout(rect = [0, 0, 1, 0.988])\n",
    "plt.savefig('data/visualizations/Cost_PerfomanceAcrossModels.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like for most models, the HistGradientBoostingClassifier does almost the same as the Random Forest Classifier but does slightly better than the LogisticRegression model in for all subpopulations and all patients. Let's train each subpopulation on their best parameters for HistGradientBoostingClassifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_scores = []\n",
    "\n",
    "for drg in ['all', 194.0, 140.0, 750.0, 463.0, 302.0]:\n",
    "    subpop_df = load_data(drg, data_file_path)\n",
    "    subpop_df['Total Costs Bin'] = pd.cut(x = subpop_df['Total Costs'], bins = bins, \n",
    "                                          labels = labels, include_lowest = True)      \n",
    "    X, y, X_train, X_test, y_train, y_test = get_cost_train_test_data(subpop_df)\n",
    "\n",
    "    best_params = scores_gb_df.loc[(scores_gb_df['model']=='HistGradientBoost') & \n",
    "                                   (scores_gb_df['subpopulation']==drg)]['best_params'].values[0]\n",
    "    model_scores = get_cost_model_scores(best_params, X_train, X_test, y_train, y_test)\n",
    "    final_model_scores.append({\n",
    "        'Population': drg,\n",
    "        'Accuracy Score': model_scores[0],\n",
    "        'F1_score_macro': model_scores[1],\n",
    "        'F1_score_weighted': model_scores[2],\n",
    "        'Model':'HistGradientBoost'\n",
    "    })\n",
    "\n",
    "final_results_df = pd.DataFrame(final_model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the results\n",
    "#Build visualization comparing random forest model performance of all populations\n",
    "colors = ['orangered' if (x == 'all') else 'skyblue' for x in final_results_df['Population'].values]\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 12), sharey=False)\n",
    "fig.subplots_adjust(hspace=0.45, wspace=0.25)\n",
    "fig.suptitle('Comparison of Random Forest Model Performance Across Patient Populations\\n(Total Cost)', fontsize=17, fontweight='bold')\n",
    "\n",
    "sns.barplot(ax=axes[0], x=final_results_df['Population'], y=final_results_df['F1_score_macro'], palette=colors)\n",
    "axes[0].set_xlabel('Subpopulation (DRG Code)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('F1 Macro Score', fontsize=12, fontweight='bold')\n",
    "axes[0].bar_label(axes[0].containers[0], fmt='%.2f', padding=2, fontsize=12)\n",
    "axes[0].set_xticklabels(labels=['All', 'Heart Failure\\n(DRG 194)', 'COPD\\n(DRG 140)', 'Schizophrenia\\n(DRG 750)', 'Kidney\\\\UTI\\n(DRG 463)', 'Knee Joint\\nReplacement\\n(DRG 302)'], fontsize=12)\n",
    "axes[0].set_title('F1 Macro Score Across Populations', fontweight='bold', fontsize=14)\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "sns.barplot(ax=axes[1], x=final_results_df['Population'], y=final_results_df['F1_score_weighted'], palette=colors)\n",
    "axes[1].set_xlabel('Subpopulation (DRG Code)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('F1 Weighted Score', fontsize=12, fontweight='bold')\n",
    "axes[1].bar_label(axes[1].containers[0], fmt='%.2f', fontsize=12)\n",
    "axes[1].set_xticklabels(labels=['All', 'Heart Failure\\n(DRG 194)', 'COPD\\n(DRG 140)', 'Schizophrenia\\n(DRG 750)', 'Kidney\\\\UTI\\n(DRG 463)', 'Knee Joint\\nReplacement\\n(DRG 302)'], fontsize=12)\n",
    "axes[1].set_title('F1 Weighted Score Across Populations', fontweight='bold', fontsize=14)\n",
    "axes[1].set_ylim(0, 1)\n",
    "\n",
    "sns.barplot(ax=axes[2], x=final_results_df['Population'], y=final_results_df['Accuracy Score'], palette=colors)\n",
    "axes[2].set_xlabel('Subpopulation (DRG Code)', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylabel('Accuracy Score', fontsize=12, fontweight='bold')\n",
    "axes[2].bar_label(axes[2].containers[0], fmt='%.2f', fontsize=12)\n",
    "axes[2].set_xticklabels(labels=['All', 'Heart Failure\\n(DRG 194)', 'COPD\\n(DRG 140)', 'Schizophrenia\\n(DRG 750)', 'Kidney\\\\UTI\\n(DRG 463)', 'Knee Joint\\nReplacement\\n(DRG 302)'], fontsize=12)\n",
    "axes[2].set_title('Accuracy Score Across Populations', fontweight='bold', fontsize=14)\n",
    "axes[2].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout(rect = [0, 0, 1, 0.988])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the visualization above, it can be seen that for F1 macro scores the model built on all conditions of interest outperforms models trained only on patients with a specific DRG code with the exception of Knee replacement patients.\n",
    "<br /><br />\n",
    "Let's also compare performance with a dummy classifier which predicts the majority class every time and a dummy classifier which selects a class at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dummy model performance on all the population datasets\n",
    "final_model_scores = []\n",
    "\n",
    "#all population\n",
    "for drg in ['all', 194.0, 140.0, 750.0, 463.0, 302.0]:\n",
    "    print(drg)\n",
    "    subpop_df = load_data(drg, data_file_path)\n",
    "    subpop_df['Total Costs Bin'] = pd.cut(x = subpop_df['Total Costs'], bins = bins, \n",
    "                                          labels = labels, include_lowest = True) \n",
    "    X, y, X_train, X_test, y_train, y_test = get_cost_train_test_data(subpop_df)\n",
    "    \n",
    "    most_freq_dummy_scores = get_dummy_scores(\"most_frequent\", X_train, X_test, y_train, y_test)\n",
    "\n",
    "    final_model_scores.append({\n",
    "        'Population': drg,\n",
    "        'Model': 'DummyClassifier - Most Frequent',\n",
    "        'Accuracy Score': most_freq_dummy_scores[0],\n",
    "        'F1_score_macro': most_freq_dummy_scores[1],\n",
    "        'F1_score_weighted': most_freq_dummy_scores[2]\n",
    "    })\n",
    "\n",
    "    random_dummy_scores = get_dummy_scores(\"uniform\", X_train, X_test, y_train, y_test)\n",
    "\n",
    "    final_model_scores.append({\n",
    "        'Population': drg,\n",
    "        'Model': 'DummyClassifier - Random',\n",
    "        'Accuracy Score': random_dummy_scores[0],\n",
    "        'F1_score_macro': random_dummy_scores[1],\n",
    "        'F1_score_weighted': random_dummy_scores[2]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores_df = pd.DataFrame(final_model_scores)\n",
    "final_results_with_dummy_df = pd.concat([final_results_df, final_scores_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot dummy classifiers vs rf model performance for each population\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 15), sharey=False)\n",
    "fig.subplots_adjust(hspace=0.45, wspace=0.25)\n",
    "fig.suptitle('Scores of Trained Random Forest Model vs. Dummy Models By Subpopulation\\n(Total Cost)', fontsize=17, fontweight='bold')\n",
    "\n",
    "sns.barplot(ax=axes[0], data=final_results_with_dummy_df, x=\"Population\", y=\"F1_score_macro\", \n",
    "            hue=\"Model\",palette= ['orangered','skyblue', '#5CED73'])\n",
    "axes[0].set_xlabel('Subpopulation', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('F1 Macro Score', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticklabels(labels=['All', 'Heart Failure\\n(DRG 194)', 'COPD\\n(DRG 140)', 'Schizophrenia\\n(DRG 750)', 'Kidney\\\\UTI\\n(DRG 463)', 'Knee Joint\\nReplacement\\n(DRG 302)'], fontsize=14)\n",
    "axes[0].set_title('F1 Macro Scores', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylim(0, 0.5)\n",
    "current_values_y = axes[0].get_yticks()\n",
    "axes[0].set_yticklabels([round(x, 2) for x in current_values_y], fontsize=14)\n",
    "axes[0].legend(fontsize=12)\n",
    "\n",
    "sns.barplot(ax=axes[1], data=final_results_with_dummy_df, x=\"Population\", y=\"F1_score_weighted\", \n",
    "            hue=\"Model\",palette= ['orangered','#5CED73', 'skyblue', '#5CED73'])\n",
    "axes[1].set_xlabel('Subpopulation', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('F1 Weighted Score', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticklabels(labels=['All', 'Heart Failure\\n(DRG 194)', 'COPD\\n(DRG 140)', 'Schizophrenia\\n(DRG 750)', 'Kidney\\\\UTI\\n(DRG 463)', 'Knee Joint\\nReplacement\\n(DRG 302)'], fontsize=14)\n",
    "axes[1].set_title('F1 Weighted Scores', fontsize=14, fontweight='bold')\n",
    "current_values_y = axes[1].get_yticks()\n",
    "axes[1].set_yticklabels([round(x, 2) for x in current_values_y], fontsize=14)\n",
    "axes[1].legend(fontsize=12)\n",
    "\n",
    "sns.barplot(ax=axes[2], data=final_results_with_dummy_df, x=\"Population\", y=\"Accuracy Score\", \n",
    "            hue=\"Model\",palette= ['orangered', '#5CED73','skyblue', '#5CED73'])\n",
    "axes[2].set_xlabel('Subpopulation', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylabel('Accuracy Score', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xticklabels(labels=['All', 'Heart Failure\\n(DRG 194)', 'COPD\\n(DRG 140)', 'Schizophrenia\\n(DRG 750)', 'Kidney\\\\UTI\\n(DRG 463)', 'Knee Joint\\nReplacement\\n(DRG 302)'], fontsize=14)\n",
    "axes[2].set_title('Accuracy Scores', fontsize=14, fontweight='bold')\n",
    "current_values_y = axes[2].get_yticks()\n",
    "axes[2].set_yticklabels([round(x, 2) for x in current_values_y], fontsize=14)\n",
    "axes[2].legend(fontsize=12)\n",
    "\n",
    "for ax1 in [axes[0], axes[1], axes[2]]:\n",
    "    for c in ax1.containers:\n",
    "        # set the bar label\n",
    "        ax1.bar_label(c, fmt='%.2f', fontsize=14)\n",
    "\n",
    "plt.tight_layout(rect = [0, 0, 1, 0.988])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models do outperform the dummy models, especially when comparing the F1 Macro score. However, overall we can see that the F1 macro scores are still fairly low for the trained models.\n",
    "\n",
    "<br /><br />\n",
    "As a next step, we will be performing Oversampling, because of the performance time of this, it has been commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment to run this cell\n",
    "\n",
    "oversample_scores = []\n",
    "\n",
    "oversample = SMOTE()\n",
    "best_params = scores_gb_df.loc[(scores_gb_df['model']=='HistGradientBoost') & (scores_gb_df['subpopulation']=='all')]['best_params'].values[0]\n",
    "\n",
    "subpop_df = load_data('all', data_file_path)\n",
    "subpop_df['Total Costs Bin'] = pd.cut(x = subpop_df['Total Costs'], bins = bins, \n",
    "                                           labels = labels, include_lowest = True)\n",
    "\n",
    "X, y, X_train, X_test, y_train, y_test = get_cost_train_test_data(subpop_df)\n",
    "\n",
    "X_train_resample, y_train_resample = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "oversampled_model = train_cost_model(best_params, X_train_resample, y_train_resample)\n",
    "\n",
    "oversample_scores.append({\n",
    "     'Population': 'all',\n",
    "     'Model': 'Upsampled',\n",
    "     'Accuracy Score': model_scores[0],\n",
    "     'F1_score_macro': model_scores[1],\n",
    "     'F1_score_weighted': model_scores[2]\n",
    "})\n",
    "\n",
    "final_results_df = final_results_df.append(oversample_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot dummy classifiers vs rf model performance for each population\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 8), sharey=True)\n",
    "fig.subplots_adjust(hspace=0.45, wspace=0.25)\n",
    "fig.suptitle('Scores of Hist Gradient Boost Classifier Trained on Upsampled vs Original Data\\n(Total Cost)', fontsize=16, fontweight='bold')\n",
    "\n",
    "final_results_upsampled = final_results_df[final_results_df['Population'] == 'all']\n",
    "sns.barplot(ax=axes[0], data=final_results_df, x=\"Model\", y=\"F1_score_macro\", palette= ['orangered', 'skyblue'], ci=None)\n",
    "axes[0].set_xlabel('Model Type', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('F1 Macro Score', fontsize=14, fontweight='bold')\n",
    "axes[0].bar_label(axes[0].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[0].set_title('F1 Macro Scores', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticklabels(labels=['Hist Gradient\\nBoost\\nClassifier', 'Hist Gradient\\nBoost\\nClassifier\\nUpsampled'], fontsize=14)\n",
    "\n",
    "sns.barplot(ax=axes[1], data=final_results_df, x=\"Model\", y=\"F1_score_weighted\", palette= ['orangered', 'skyblue'], ci=None)\n",
    "axes[1].set_xlabel('Model Type', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('F1 Weighted Score', fontsize=14, fontweight='bold')\n",
    "axes[1].bar_label(axes[1].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[1].set_title('F1 Weighted Scores', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticklabels(labels=['Hist Gradient\\nBoost\\nClassifier', 'Hist Gradient\\nBoost\\nClassifier\\nUpsampled'], fontsize=14)\n",
    "\n",
    "\n",
    "sns.barplot(ax=axes[2], data=final_results_df, x=\"Model\", y=\"Accuracy Score\", palette= ['orangered', 'skyblue'], ci=None)\n",
    "axes[2].set_xlabel('Model Type', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylabel('Accuracy Score', fontsize=14, fontweight='bold')\n",
    "axes[2].bar_label(axes[2].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[2].set_title('Accuracy Scores', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xticklabels(labels=['Hist Gradient\\nBoost\\nClassifier', 'Hist Gradient\\nBoost\\nClassifier\\nUpsampled'], fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "eabca979b0553fa6d87e9a00c352604d3b703d4afc9641643dd42376492b80f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
