{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Length of Stay Model Building and Exploration</h3><br />\n",
    "This notebook shows the process of building classification models for length of stay. It shows the performance of models with different bin sizes, different models, and upsampling techniques. This notebook also contains an evaluation of model performance across sub-populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all needed models\n",
    "import sys\n",
    "import platform\n",
    "plat = platform.system()\n",
    "if plat == 'Windows':\n",
    "    sys.path.insert(0, '..\\src\\helpers')\n",
    "    sys.path.insert(0, '..\\src\\models')\n",
    "elif plat =='Linux' or plat=='Darwin':\n",
    "    sys.path.insert(0, '../src/helpers')\n",
    "    sys.path.insert(0, '../src/models')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import log_loss, f1_score, classification_report, make_scorer, precision_score, recall_score, accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from data_cleaners import *\n",
    "from model_building_helpers import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all patient csv (csv containing data for all the indications (COPD, Heart Failure, Schizophrenia, Knee Replacement, Kidney/UTI))\n",
    "data_file_path = '../data'\n",
    "all_patient_df = load_data('All', data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following two cells to see how changing the bin definitions changes the accuracy and confusion matrix of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bin the data by length of stay ranges\n",
    "bins = [1, 5, 15, 30, 45, 60, 90, 120]\n",
    "labels = ['1 to 5', '6 to 15', '16 to 30', '31 to 45', '46 to 60', '60 to 90', '90 to 120']\n",
    "\n",
    "all_patient_df_bins = all_patient_df.copy()\n",
    "all_patient_df_bins['Length of Stay Bin'] = pd.cut(x = all_patient_df_bins['Length of Stay'], bins = bins, labels = labels, include_lowest = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_train, X_test, y_train, y_test = get_train_test_data(all_patient_df_bins)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, np.ravel(y_train))\n",
    "y_pred = model.predict(X_test)\n",
    "bin1_accuracy = accuracy_score(y_test, y_pred)\n",
    "bin1_f1_score_macro = f1_score(y_test, y_pred, average='macro')\n",
    "bin1_f1_score_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy = \", bin1_accuracy, \"\\nF1 Macro Score = \", bin1_f1_score_macro, \"\\nF1 Weighted Score = \", bin1_f1_score_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the confusion matrix as a heart map\n",
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix), index = [i for i in labels],\n",
    "                  columns = [i for i in labels])\n",
    "plt.figure(figsize = (12, 12))\n",
    "plt.title('Confusion Matrix For Random Forest Model', fontsize=17, weight='bold', pad=30)\n",
    "sns.heatmap(df_cm, annot=True, fmt='.2%',  cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get RandomForest best parameters and best score by sub-population\n",
    "#Experiment model performance by changing the parameters tested and interations for the RandomizedSearch\n",
    "rf_scores = []\n",
    "iterations = 10 #We found the iterations did not affect F1 macro scores much, so we used the default of 10\n",
    "\n",
    "for drg in ['all', 194.0, 140.0, 750.0, 463.0, 302.0]:\n",
    "    subpop_df = load_data(drg, data_file_path)\n",
    "    subpop_df['Length of Stay Bin'] = pd.cut(x = subpop_df['Length of Stay'], bins = bins, labels = labels, include_lowest = True)\n",
    "    if len(subpop_df) > 30000:\n",
    "        subpop_df = subpop_df.groupby('Length of Stay Bin', group_keys=False).apply(lambda x: x.sample(int(np.rint(30000*len(x)/len(subpop_df))))).sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "    X, y, X_train, X_test, y_train, y_test = get_train_test_data(subpop_df)\n",
    "\n",
    "    random_grid = {'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 800, num = 15)],\n",
    "               'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False],\n",
    "               'class_weight': ['balanced', 'balanced_subsample']}\n",
    "    \n",
    "    best_params, best_score = get_best_rf_params(X_train, y_train, random_grid, iterations)\n",
    "    rf_scores.append({drg:{\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score\n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get LogisticRegression best parameters and best score by sub-population\n",
    "#Experiment model performance by changing the parameters tested and interations for the RandomizedSearch\n",
    "lr_scores = []\n",
    "iterations = 10 #We found the iterations did not affect F1 macro scores much, so we used the default of 10\n",
    "\n",
    "for drg in ['all', 194.0, 140.0, 750.0, 463.0, 302.0]:\n",
    "    subpop_df = load_data(drg, data_file_path)\n",
    "    subpop_df['Length of Stay Bin'] = pd.cut(x = subpop_df['Length of Stay'], bins = bins, labels = labels, include_lowest = True)\n",
    "    if len(subpop_df) > 30000:\n",
    "        subpop_df = subpop_df.groupby('Length of Stay Bin', group_keys=False).apply(lambda x: x.sample(int(np.rint(30000*len(x)/len(subpop_df))))).sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "    X, y, X_train, X_test, y_train, y_test = get_train_test_data(subpop_df)\n",
    "\n",
    "    random_grid = {'C' : np.logspace(0, 4, num=10),\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'solver' : ['liblinear'],\n",
    "    'class_weight': ['balanced', None]}\n",
    "    \n",
    "    best_params, best_score = get_best_lr_params(X_train, y_train, random_grid, iterations)\n",
    "    lr_scores.append({drg:{\n",
    "            'best_params': best_params,\n",
    "            'best_score': best_score\n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_rf_df = pd.DataFrame(columns=['model', 'subpopulation', 'best_params', 'best_scores'])\n",
    "for item in rf_scores:\n",
    "    for key, item in item.items():\n",
    "        scores_rf_df = scores_rf_df.append({'model': 'RandomForestClassifier', 'subpopulation': key, 'best_params': item['best_params'], 'best_scores': item['best_score']}, ignore_index=True)\n",
    "\n",
    "\n",
    "scores_lr_df = pd.DataFrame(columns=['model', 'subpopulation', 'best_params', 'best_scores'])\n",
    "for item in lr_scores:\n",
    "    for key, item in item.items():\n",
    "        scores_lr_df = scores_lr_df.append({'model': 'LogisticRegression', 'subpopulation': key, 'best_params': item['best_params'], 'best_scores': item['best_score']}, ignore_index=True)\n",
    "\n",
    "\n",
    "randomized_search_results = pd.concat([scores_rf_df,scores_lr_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create visualization for each subpopulation for each model\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10), sharey=True)\n",
    "\n",
    "fig.subplots_adjust(hspace=0.45, wspace=0.25)\n",
    "\n",
    "\n",
    "fig.suptitle('F1 - Macro Scores For RandomForestClassifier vs. LogisticRegression\\n(Length of Stay)', fontsize=17, weight='bold')\n",
    "\n",
    "all_patients = randomized_search_results[randomized_search_results['subpopulation'] == 'all']\n",
    "heart_patients = randomized_search_results[randomized_search_results['subpopulation'] == 194.0]\n",
    "copd_patients = randomized_search_results[randomized_search_results['subpopulation'] == 140.0]\n",
    "schizophrenia_patients = randomized_search_results[randomized_search_results['subpopulation'] == 750.0]\n",
    "kidney_patients = randomized_search_results[randomized_search_results['subpopulation'] == 463.0]\n",
    "knee_rep_patients = randomized_search_results[randomized_search_results['subpopulation'] == 302.0]\n",
    "\n",
    "sns.barplot(ax=axes[0, 0], x=all_patients['model'], y=all_patients['best_scores'], palette=['#5CED73', 'skyblue'])\n",
    "axes[0, 0].set_xlabel('Model Type', fontweight='bold', fontsize=14)\n",
    "axes[0, 0].set_ylabel('F1 Score', fontweight='bold', fontsize=14)\n",
    "axes[0, 0].bar_label(axes[0, 0].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[0, 0].set_xticklabels(labels=['Random Forest\\nClassifier', 'Logistic\\nRegression'], fontsize=14)\n",
    "axes[0, 0].set_title('All Patients', fontweight='bold', fontsize=16)\n",
    "current_values_y = axes[0, 0].get_yticks()\n",
    "axes[0, 0].set_yticklabels([round(x, 2) for x in current_values_y], fontsize=14)\n",
    "\n",
    "sns.barplot(ax=axes[0, 1], x=heart_patients['model'], y=heart_patients['best_scores'], palette=['#5CED73', 'skyblue'])\n",
    "axes[0, 1].set_xlabel('Model Type', fontweight='bold', fontsize=14)\n",
    "axes[0, 1].set_ylabel('F1 Score', fontweight='bold', fontsize=14)\n",
    "axes[0, 1].bar_label(axes[0, 1].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[0,1].set_xticklabels(labels=['Random Forest\\nClassifier', 'Logistic\\nRegression'], fontsize=14)\n",
    "axes[0, 1].set_title('Patients with DRG Code 194\\n(Heart Failure)', fontweight='bold', fontsize=16)\n",
    "\n",
    "sns.barplot(ax=axes[0, 2], x=copd_patients['model'], y=copd_patients['best_scores'], palette=['#5CED73', 'skyblue'])\n",
    "axes[0, 2].set_xlabel('Model Type', fontweight='bold', fontsize=14)\n",
    "axes[0, 2].set_ylabel('F1 Score', fontweight='bold', fontsize=14)\n",
    "axes[0, 2].bar_label(axes[0, 2].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[0, 2].set_xticklabels(labels=['Random Forest\\nClassifier', 'Logistic\\nRegression'], fontsize=14)\n",
    "axes[0, 2].set_title('Patients with DRG Code 140\\n(COPD)', fontweight='bold', fontsize=16)\n",
    "\n",
    "sns.barplot(ax=axes[1, 0], x=schizophrenia_patients['model'], y=schizophrenia_patients['best_scores'], palette=['#5CED73', 'skyblue'])\n",
    "axes[1, 0].set_xlabel('Model Type', fontweight='bold', fontsize=12)\n",
    "axes[1, 0].set_ylabel('F1 Score', fontweight='bold', fontsize=12)\n",
    "axes[1, 0].bar_label(axes[1, 0].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[1, 0].set_xticklabels(labels=['Random Forest\\nClassifier', 'Logistic\\nRegression'],  fontsize=14)\n",
    "axes[1, 0].set_title('Patients with DRG Code 750\\n(Schizophrenia)', fontweight='bold', fontsize=16)\n",
    "current_values_y = axes[1, 0].get_yticks()\n",
    "axes[1, 0].set_yticklabels([round(x, 2) for x in current_values_y], fontsize=14)\n",
    "\n",
    "sns.barplot(ax=axes[1, 1], x=kidney_patients['model'], y=kidney_patients['best_scores'], palette=['#5CED73', 'skyblue'])\n",
    "axes[1, 1].set_xlabel('Model Type', fontweight='bold', fontsize=14)\n",
    "axes[1, 1].set_ylabel('F1 Score', fontweight='bold', fontsize=14)\n",
    "axes[1, 1].bar_label(axes[1, 1].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[1, 1].set_xticklabels(labels=['Random Forest\\nClassifier', 'Logistic\\nRegression'], fontsize=14)\n",
    "axes[1, 1].set_title('Patients with DRG Code 463\\n(Kidney/UTI)', fontweight='bold', fontsize=16)\n",
    "\n",
    "sns.barplot(ax=axes[1, 2], x=knee_rep_patients['model'], y=knee_rep_patients['best_scores'], palette=['#5CED73', 'skyblue'])\n",
    "axes[1, 2].set_xlabel('Model Type', fontsize=14, fontweight='bold')\n",
    "axes[1, 2].set_ylabel('F1 Score', fontsize=14, fontweight='bold')\n",
    "axes[1, 2].bar_label(axes[1, 2].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[1, 2].set_xticklabels(labels=['Random Forest\\nClassifier', 'Logistic\\nRegression'], fontsize=14)\n",
    "axes[1, 2].set_title('Patients with DRG Code 302\\n(Knee Joint Replacement)', fontweight='bold', fontsize=16)\n",
    "\n",
    "axes[1, 2].set_ylim(0, 0.5)\n",
    "\n",
    "plt.tight_layout(rect = [0, 0, 1, 0.988])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like for most models, the RandomForestClassifier does as good or better than the LogisticRegression model, with the exception of the models trained on Knee Replacement patients. Let's train each subpopulation on their best parameters for RandomForestClassifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_scores = []\n",
    "\n",
    "for drg in ['all', 194.0, 140.0, 750.0, 463.0, 302.0]:\n",
    "    subpop_df = load_data(drg, data_file_path)\n",
    "    subpop_df['Length of Stay Bin'] = pd.cut(x = subpop_df['Length of Stay'], bins = bins, labels = labels, include_lowest = True)\n",
    "      \n",
    "    X, y, X_train, X_test, y_train, y_test = get_train_test_data(subpop_df)\n",
    "\n",
    "    best_params = scores_rf_df.loc[(scores_rf_df['model']=='RandomForestClassifier') & (scores_rf_df['subpopulation']==drg)]['best_params'].values[0]\n",
    "    model_scores = get_model_scores(best_params, X_train, X_test, y_train, y_test)\n",
    "    final_model_scores.append({\n",
    "        'Model': 'RandomForestClassifier',\n",
    "        'Population': drg,\n",
    "        'Accuracy Score': model_scores[0],\n",
    "        'F1_score_macro': model_scores[1],\n",
    "        'F1_score_weighted': model_scores[2]\n",
    "    })\n",
    "\n",
    "final_results_df = pd.DataFrame(final_model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the results\n",
    "#Build visualization comparing random forest model performance of all populations\n",
    "colors = ['orangered' if (x == 'all') else 'skyblue' for x in final_results_df['Population'].values]\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 16), sharey=True)\n",
    "fig.subplots_adjust(hspace=0.45, wspace=0.25)\n",
    "fig.suptitle('Comparison of Random Forest Model Performance Across Patient Populations\\n(Length of Stay)', fontsize=17, fontweight='bold')\n",
    "\n",
    "sns.barplot(ax=axes[0], x=final_results_df['Population'], y=final_results_df['F1_score_macro'], palette=colors)\n",
    "axes[0].set_xlabel('Subpopulation (DRG Code)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('F1 Macro Score', fontsize=12, fontweight='bold')\n",
    "axes[0].bar_label(axes[0].containers[0], fmt='%.2f', padding=2, fontsize=12)\n",
    "axes[0].set_xticklabels(labels=['All', 'Heart Failure\\n(DRG 194)', 'COPD\\n(DRG 140)', 'Schizophrenia\\n(DRG 750)', 'Kidney\\\\UTI\\n(DRG 463)', 'Knee Joint\\nReplacement\\n(DRG 302)'], fontsize=12)\n",
    "axes[0].set_title('F1 Macro Score Across Populations', fontweight='bold', fontsize=14)\n",
    "axes[0].set_ylim(0, 1)\n",
    "current_values_y = axes[0].get_yticks()\n",
    "axes[0].set_yticklabels([round(x, 2) for x in current_values_y], fontsize=12)\n",
    "\n",
    "sns.barplot(ax=axes[1], x=final_results_df['Population'], y=final_results_df['F1_score_weighted'], palette=colors)\n",
    "axes[1].set_xlabel('Subpopulation (DRG Code)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('F1 Weighted Score', fontsize=12, fontweight='bold')\n",
    "axes[1].bar_label(axes[1].containers[0], fmt='%.2f', fontsize=12)\n",
    "axes[1].set_xticklabels(labels=['All', 'Heart Failure\\n(DRG 194)', 'COPD\\n(DRG 140)', 'Schizophrenia\\n(DRG 750)', 'Kidney\\\\UTI\\n(DRG 463)', 'Knee Joint\\nReplacement\\n(DRG 302)'], fontsize=12)\n",
    "axes[1].set_title('F1 Weighted Score Across Populations', fontweight='bold', fontsize=14)\n",
    "axes[1].set_ylim(0, 1)\n",
    "current_values_y = axes[1].get_yticks()\n",
    "axes[1].set_yticklabels([round(x, 2) for x in current_values_y], fontsize=12)\n",
    "\n",
    "sns.barplot(ax=axes[2], x=final_results_df['Population'], y=final_results_df['Accuracy Score'], palette=colors)\n",
    "axes[2].set_xlabel('Subpopulation (DRG Code)', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylabel('Accuracy Score', fontsize=12, fontweight='bold')\n",
    "axes[2].bar_label(axes[2].containers[0], fmt='%.2f', fontsize=12)\n",
    "axes[2].set_xticklabels(labels=['All', 'Heart Failure\\n(DRG 194)', 'COPD\\n(DRG 140)', 'Schizophrenia\\n(DRG 750)', 'Kidney\\\\UTI\\n(DRG 463)', 'Knee Joint\\nReplacement\\n(DRG 302)'], fontsize=12)\n",
    "axes[2].set_title('Accuracy Score Across Populations', fontweight='bold', fontsize=14)\n",
    "axes[2].set_ylim(0, 1)\n",
    "current_values_y = axes[2].get_yticks()\n",
    "axes[2].set_yticklabels([round(x, 2) for x in current_values_y], fontsize=12)\n",
    "\n",
    "plt.tight_layout(rect = [0, 0, 1, 0.988])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the visualization above, it can be seen that for F1 macro scores the model built on all conditions of interest outperforms models trained only on patients with a specific DRG code with the exception of Knee replacement patients.\n",
    "<br /><br />\n",
    "Let's also compare performance with a dummy classifier which predicts the majority class every time and a dummy classifier which selects a class at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dummy model performance on all the population datasets\n",
    "final_model_scores = []\n",
    "\n",
    "#all population\n",
    "for drg in ['all', 194.0, 140.0, 750.0, 463.0, 302.0]:\n",
    "    print(drg)\n",
    "    subpop_df = load_data(drg, data_file_path)\n",
    "    subpop_df['Length of Stay Bin'] = pd.cut(x = subpop_df['Length of Stay'], bins = bins, labels = labels, include_lowest = True)\n",
    "      \n",
    "    X, y, X_train, X_test, y_train, y_test = get_train_test_data(subpop_df)\n",
    "    \n",
    "    most_freq_dummy_scores = get_dummy_scores(\"most_frequent\", X_train, X_test, y_train, y_test)\n",
    "\n",
    "    final_model_scores.append({\n",
    "        'Population': drg,\n",
    "        'Model': 'DummyClassifier - Most Frequent',\n",
    "        'Accuracy Score': most_freq_dummy_scores[0],\n",
    "        'F1_score_macro': most_freq_dummy_scores[1],\n",
    "        'F1_score_weighted': most_freq_dummy_scores[2]\n",
    "    })\n",
    "\n",
    "    random_dummy_scores = get_dummy_scores(\"uniform\", X_train, X_test, y_train, y_test)\n",
    "\n",
    "    final_model_scores.append({\n",
    "        'Population': drg,\n",
    "        'Model': 'DummyClassifier - Random',\n",
    "        'Accuracy Score': random_dummy_scores[0],\n",
    "        'F1_score_macro': random_dummy_scores[1],\n",
    "        'F1_score_weighted': random_dummy_scores[2]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores_df = pd.DataFrame(final_model_scores)\n",
    "final_results_with_dummy_df = pd.concat([final_results_df, final_scores_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot dummy classifiers vs rf model performance for each population\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 18), sharey=True)\n",
    "fig.subplots_adjust(hspace=0.45, wspace=0.25)\n",
    "fig.suptitle('Scores of Trained Random Forest Model vs. Dummy Models By Subpopulation', fontsize=16)\n",
    "\n",
    "sns.barplot(ax=axes[0], data=final_results_with_dummy_df, x=\"Population\", y=\"F1_Macro\", hue=\"Model\",palette= ['orangered', 'skyblue', '#5CED73'])\n",
    "axes[0].set_xlabel('Subpopulation', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('F1 Macro Score', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xticklabels(labels=['All', 'Heart Failure\\n(DRG 194)', 'COPD\\n(DRG 140)', 'Schizophrenia\\n(DRG 750)', 'Kidney\\\\UTI\\n(DRG 463)', 'Knee Joint\\nReplacement\\n(DRG 302)'], fontsize=14)\n",
    "axes[0].set_title('F1 Macro Scores', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylim(0, 0.5)\n",
    "current_values_y = axes[0].get_yticks()\n",
    "axes[0].set_yticklabels([round(x, 2) for x in current_values_y], fontsize=14)\n",
    "axes[0].legend(fontsize=12)\n",
    "\n",
    "sns.barplot(ax=axes[1], data=final_results_with_dummy_df, x=\"Population\", y=\"F1_score_weighted\", hue=\"Model\",palette= ['orangered', 'skyblue', '#5CED73'])\n",
    "axes[1].set_xlabel('Subpopulation', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('F1 Weighted Score', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xticklabels(labels=['All', 'Heart Failure\\n(DRG 194)', 'COPD\\n(DRG 140)', 'Schizophrenia\\n(DRG 750)', 'Kidney\\\\UTI\\n(DRG 463)', 'Knee Joint\\nReplacement\\n(DRG 302)'], fontsize=14)\n",
    "axes[1].set_title('F1 Weighted Scores', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylim(0, 0.5)\n",
    "current_values_y = axes[1].get_yticks()\n",
    "axes[1].set_yticklabels([round(x, 2) for x in current_values_y], fontsize=14)\n",
    "axes[1].legend(fontsize=12)\n",
    "\n",
    "sns.barplot(ax=axes[2], data=final_results_with_dummy_df, x=\"Population\", y=\"Accuracy Score\", hue=\"Model\",palette= ['orangered', 'skyblue', '#5CED73'])\n",
    "axes[2].set_xlabel('Subpopulation', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylabel('Accuracy Score', fontsize=12, fontweight='bold')\n",
    "axes[2].set_xticklabels(labels=['All', 'Heart Failure\\n(DRG 194)', 'COPD\\n(DRG 140)', 'Schizophrenia\\n(DRG 750)', 'Kidney\\\\UTI\\n(DRG 463)', 'Knee Joint\\nReplacement\\n(DRG 302)'], fontsize=14)\n",
    "axes[2].set_title('Accuracy Scores', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylim(0, 0.5)\n",
    "current_values_y = axes[2].get_yticks()\n",
    "axes[2].set_yticklabels([round(x, 2) for x in current_values_y], fontsize=14)\n",
    "axes[2].legend(fontsize=12)\n",
    "\n",
    "for ax1 in [axes[0], axes[1], axes[2]]:\n",
    "    for c in ax1.containers:\n",
    "        # set the bar label\n",
    "        ax1.bar_label(c, fmt='%.2f', fontsize=14)\n",
    "\n",
    "plt.tight_layout(rect = [0, 0, 1, 0.988])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models do outperform the dummy models, especially when comparing the F1 Macro score. However, overall we can see that the F1 macro scores are still fairly low for the trained models. This is due to the class imbalance we see in the dataset. About 65% of patients stay in the hospital 1 - 5 days. This is about the same as our accuracy and weighted F1 scores.\n",
    "<br /><br />\n",
    "As a next step, let's see if upsampling our tarining data for the 'All patients' model makes a difference to the F1 macro score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample_scores = []\n",
    "\n",
    "oversample = SMOTE()\n",
    "\n",
    "best_params = scores_rf_df.loc[(scores_rf_df['model']=='RandomForestClassifier') & (scores_rf_df['subpopulation']=='all')]['best_params'].values[0]\n",
    "\n",
    "subpop_df = load_data('all', data_file_path)\n",
    "subpop_df['Length of Stay Bin'] = pd.cut(x = subpop_df['Length of Stay'], bins = bins, labels = labels, include_lowest = True)\n",
    "      \n",
    "X, y, X_train, X_test, y_train, y_test = get_train_test_data(subpop_df)\n",
    "\n",
    "X_train_resample, y_train_resample = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "oversampled_model = train_model(best_params, X_train_resample, y_train_resample)\n",
    "\n",
    "model_scores = calculate_scores(oversampled_model, X_test, y_test)\n",
    "\n",
    "oversample_scores.append({\n",
    "    'Population': 'all',\n",
    "    'Model': 'RandomForestClassifier - Upsampled',\n",
    "    'Accuracy Score': model_scores[0],\n",
    "    'F1_score_macro': model_scores[1],\n",
    "    'F1_score_weighted': model_scores[2]\n",
    "})\n",
    "\n",
    "final_results_df = final_results_df.append(oversample_scores)\n",
    "final_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_df.to_csv('../src/visualizations/saved_scores_to_plot/los_oversample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot dummy classifiers vs rf model performance for each population\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 8), sharey=True)\n",
    "fig.subplots_adjust(hspace=0.45, wspace=0.25)\n",
    "fig.suptitle('Scores of RandomForestClassifier Trained on Upsampled vs Original Data\\n(Length of Stay)', fontsize=16, fontweight='bold')\n",
    "\n",
    "final_results_upsampled = final_results_df[final_results_df['Population'] == 'all']\n",
    "sns.barplot(ax=axes[0], data=final_results_df, x=\"Model\", y=\"F1_score_macro\", palette= ['orangered', 'skyblue'], ci=None)\n",
    "axes[0].set_xlabel('Model Type', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('F1 Macro Score', fontsize=14, fontweight='bold')\n",
    "axes[0].bar_label(axes[0].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[0].set_title('F1 Macro Scores', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticklabels(labels=['Random Forest\\nClassifier', 'Random Forest\\nClassifier\\nUpsampled'], fontsize=14)\n",
    "\n",
    "sns.barplot(ax=axes[1], data=final_results_df, x=\"Model\", y=\"F1_score_weighted\", palette= ['orangered', 'skyblue'], ci=None)\n",
    "axes[1].set_xlabel('Model Type', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('F1 Weighted Score', fontsize=14, fontweight='bold')\n",
    "axes[1].bar_label(axes[1].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[1].set_title('F1 Weighted Scores', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticklabels(labels=['Random Forest\\nClassifier', 'Random Forest\\nClassifier\\nUpsampled'], fontsize=14)\n",
    "\n",
    "\n",
    "sns.barplot(ax=axes[2], data=final_results_df, x=\"Model\", y=\"Accuracy Score\", palette= ['orangered', 'skyblue'], ci=None)\n",
    "axes[2].set_xlabel('Model Type', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylabel('Accuracy Score', fontsize=14, fontweight='bold')\n",
    "axes[2].bar_label(axes[2].containers[0], fmt='%.2f', padding=2, fontsize=14)\n",
    "axes[2].set_title('Accuracy Scores', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xticklabels(labels=['Random Forest\\nClassifier', 'Random Forest\\nClassifier\\nUpsampled'], fontsize=14)\n",
    "#plt.savefig('../src/visualizations/upsampled_vs_original.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'feature_names':oversampled_model.feature_names_in_,'feature_importance':oversampled_model.feature_importances_}\n",
    "features_importance_df = pd.DataFrame(data)\n",
    "features_importance_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "features_importance_df.head()\n",
    "feature_importance_to_10_df = features_importance_df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "sns_barplot = sns.barplot(x=feature_importance_to_10_df['feature_importance'], y=feature_importance_to_10_df['feature_names'], palette = ['skyblue'])\n",
    "plt.xlabel('Feature Importance', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Feature Names', fontsize=14, fontweight='bold')\n",
    "plt.title('Top 10 Feature Importances For Gradient Boosted Regressor', fontsize=17, fontweight='bold')\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.bar_label(sns_barplot.containers[0], fmt='%.3f', padding=2, fontsize=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eabca979b0553fa6d87e9a00c352604d3b703d4afc9641643dd42376492b80f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
